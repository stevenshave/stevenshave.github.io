{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    # \"proceeding\": {\n",
    "    #     \"file\" : \"proceedings.bib\",\n",
    "    #     \"venuekey\": \"booktitle\",\n",
    "    #     \"venue-pretext\": \"In the proceedings of \",\n",
    "    #     \"collection\" : {\"name\":\"publications\",\n",
    "    #                     \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    # },\n",
    "    \"journal\":{\n",
    "        \"file\": \"pubs.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taylor, P\n",
      "Blackburn, E\n",
      "Sheng, YG\n",
      "Harding, S\n",
      "Hsin, K-Y\n",
      "Kan, D\n",
      "Shave, S\n",
      "Walkinshaw, MD\n",
      "2008-01-01-Ligand-discovery-and-virtual-screening-using-the-program-LIDAEUS.md 78\n",
      "SUCESSFULLY PARSED taylor2008ligand: \" Ligand discovery and virtual screening using the program LID ... \"\n",
      "Hsin, Kun-Yi\n",
      "Morgan, Hugh P\n",
      "Shave, Steven R\n",
      "Hinton, Andrew C\n",
      "Taylor, Paul\n",
      "Walkinshaw, Malcolm D\n",
      "2011-01-01-EDULISS-a-small-molecule-database-with-data-mining-and-pharmacophore-searching-capabilities.md 105\n",
      "SUCESSFULLY PARSED hsin2011eduliss: \" EDULISS: a small-molecule database with data-mining and phar ... \"\n",
      "Teo, Chian Ying\n",
      "Shave, Steven\n",
      "Thean Chor, Adam Leow\n",
      "Salleh, Abu Bakar\n",
      "Abdul Rahman, Mohd Basyaruddin Bin\n",
      "Walkinshaw, Malcolm D\n",
      "Tejo, Bimo A\n",
      "WARNING Missing Expected Field 'journal' from entry teo2012discovery: \" Discovery of a new class of in ... \"\n",
      "Shave, Steven R\n",
      "Taylor, Paul\n",
      "Walkinshaw, M\n",
      "Smith, Lorna\n",
      "Hardy, Judy\n",
      "Trew, Arthur\n",
      "2008-01-01-Ligand-discovery-on-massively-parallel-systems.md 60\n",
      "SUCESSFULLY PARSED shave2008ligand: \" Ligand discovery on massively parallel systems  \"\n",
      "Shave, Steven R\n",
      "WARNING Missing Expected Field 'journal' from entry shave2010development: \" Development of high performanc ... \"\n",
      "Miti{\\'c}, Tijana\n",
      "Shave, Steven\n",
      "Semjonous, Nina\n",
      "McNae, Iain\n",
      "Cobice, Diego F\n",
      "Lavery, Gareth G\n",
      "Webster, Scott P\n",
      "Hadoke, Patrick WF\n",
      "Walker, Brian R\n",
      "Andrew, Ruth\n",
      "2013-01-01-11beta-Hydroxysteroid-dehydrogenase-type-1-contributes-to-the-balance-between-7-keto-and-7-hydroxy-oxysterols-in-vivo.md 131\n",
      "SUCESSFULLY PARSED mitic201311beta: \" 11$\\beta$-Hydroxysteroid dehydrogenase type 1 contributes to ... \"\n",
      "Shave, Steven\n",
      "Auer, Manfred\n",
      "2013-01-01-CSBB-ConeExclusion-adapting-structure-based-solution-virtual-screening-to-libraries-on-solid-support.md 114\n",
      "SUCESSFULLY PARSED shave2013csbb: \" CSBB-ConeExclusion, adapting structure based solution virtua ... \"\n",
      "MacGregor, Paula\n",
      "Ivens, Alasdair\n",
      "Shave, Steven\n",
      "Collie, Iain\n",
      "Gray, David\n",
      "Auer, Manfred\n",
      "Matthews, Keith R\n",
      "2014-01-01-High-throughput-chemical-screening-for-antivirulence-developmental-phenotypes-in-Trypanosoma-brucei.md 113\n",
      "SUCESSFULLY PARSED macgregor2014high: \" High-throughput chemical screening for antivirulence develop ... \"\n",
      "Hintersteiner, Martin\n",
      "Kallen, J{\\\"o}rg\n",
      "Schmied, Mario\n",
      "Graf, Christine\n",
      "Jung, Thomas\n",
      "Mudd, Gemma\n",
      "Shave, Steven\n",
      "Gstach, Hubert\n",
      "Auer, Manfred\n",
      "2014-01-01-Identifizierung-und-Strukturbestimmung-eines-niedermolekularen-Aktivators-der-LFA-1ICAM-1-Bindung.md 111\n",
      "SUCESSFULLY PARSED hintersteiner2014identifizierung: \" Identifizierung und Strukturbestimmung eines niedermolekular ... \"\n",
      "Hintersteiner, Martin\n",
      "Kallen, Joerg\n",
      "Schmied, Mario\n",
      "Graf, Christine\n",
      "Jung, Thomas\n",
      "Mudd, Gemma\n",
      "Shave, Steven\n",
      "Gstach, Hubert\n",
      "Auer, Manfred\n",
      "2014-01-01-Identification-and-X-ray-co-crystal-structure-of-a-small-molecule-activator-of-LFA-1-ICAM-1-binding.md 113\n",
      "SUCESSFULLY PARSED hintersteiner2014identification: \" Identification and X-ray co-crystal structure of a small-mol ... \"\n",
      "Gray, David\n",
      "Auer, Manfred\n",
      "Matthews, Keith R\n",
      "MacGregor, Paula\n",
      "Ivens, Alasdair\n",
      "Shave, Steven\n",
      "Collie, Iain\n",
      "2014-01-01-High-throughput-chemical-screening-for-anti-virulence-developmental-phenotypes-in-Trypanosoma-brucei.md 114\n",
      "SUCESSFULLY PARSED gray2014high: \" High throughput chemical screening for anti-virulence develo ... \"\n",
      "Shave, Steven\n",
      "Blackburn, Elizabeth A\n",
      "Adie, Jillian\n",
      "Houston, Douglas R\n",
      "Auer, Manfred\n",
      "Webster, Scott P\n",
      "Taylor, Paul\n",
      "Walkinshaw, Malcolm D\n",
      "2015-01-01-UFSRAT-ultra-fast-shape-recognition-with-atom-types-the-discovery-of-novel-bioactive-small-molecular-scaffolds-for-FKBP12-and-11betaHSD1.md 150\n",
      "SUCESSFULLY PARSED shave2015ufsrat: \" UFSRAT: ultra-fast shape recognition with atom types--the di ... \"\n",
      "McNeil, Ewan M\n",
      "Astell, Katy R\n",
      "Ritchie, Ann-Marie\n",
      "Shave, Steven\n",
      "Houston, Douglas R\n",
      "Bakrania, Preeti\n",
      "Jones, Hayley M\n",
      "Khurana, Puneet\n",
      "Wallace, Claire\n",
      "Chapman, Tim\n",
      "Wear, Martin A.\n",
      "Walkinshaw, Malcolm D.\n",
      "Saxty, Barbara\n",
      "Melton, David W.\n",
      "2015-01-01-Inhibition-of-the-ERCC1-XPF-structure-specific-endonuclease-to-overcome-cancer-chemoresistance.md 108\n",
      "SUCESSFULLY PARSED mcneil2015inhibition: \" Inhibition of the ERCC1--XPF structure-specific endonuclease ... \"\n",
      "Koszela, Joanna\n",
      "Pham, Nhan\n",
      "Evans, David\n",
      "Mann, Stefan\n",
      "Perez-Pi, Irene\n",
      "Shave, Steven\n",
      "Ceccarelli, Derek\n",
      "Sicheri, Frank\n",
      "Tyers, Mike\n",
      "Auer, Manfred\n",
      "2018-01-01-Real-time-tracking-of-complex-ubiquitination-cascades-using-a-fluorescent-confocal-on-bead-assay.md 110\n",
      "SUCESSFULLY PARSED koszela2018real: \" Real-time tracking of complex ubiquitination cascades using  ... \"\n",
      "Shave, Steven\n",
      "Mann, Stefan\n",
      "Koszela, Joanna\n",
      "Kerr, Alastair\n",
      "Auer, Manfred\n",
      "2018-01-01-PuLSE-Quality-control-and-quantification-of-peptide-sequences-explored-by-phage-display-libraries.md 111\n",
      "SUCESSFULLY PARSED shave2018pulse: \" PuLSE: Quality control and quantification of peptide sequenc ... \"\n",
      "Shave, Steven\n",
      "McGuire, Kris\n",
      "Pham, Nhan T\n",
      "Mole, Damian J\n",
      "Webster, Scott P\n",
      "Auer, Manfred\n",
      "2018-01-01-Diclofenac-identified-as-a-kynurenine-3-monooxygenase-binder-and-inhibitor-by-molecular-similarity-techniques.md 123\n",
      "SUCESSFULLY PARSED shave2018diclofenac: \" Diclofenac identified as a kynurenine 3-monooxygenase binder ... \"\n",
      "Kennedy, Susan A\n",
      "Jarboui, Mohamed-Ali\n",
      "Srihari, Sriganesh\n",
      "Raso, Cinzia\n",
      "Bryan, Kenneth\n",
      "Dernayka, Layal\n",
      "Charitou, Theodosia\n",
      "Bernal-Llinares, Manuel\n",
      "Herrera-Montavez, Carlos\n",
      "Krstic, Aleksandar\n",
      "Matallanas, David\n",
      "Kotlyar, Max\n",
      "Jurisica, Igor\n",
      "Curak, Jasna\n",
      "Wong, Victoria\n",
      "Stagljar, Igor\n",
      "LeBihan, Thierry\n",
      "Imrie, Lisa\n",
      "Pillai, Priyanka\n",
      "Lynn, Miriam A\n",
      "Fasterius, Erik\n",
      "Szigyarto, Cristina Al-Khalili\n",
      "Breen, James\n",
      "Kiel, Christina\n",
      "Serrano, Luis\n",
      "Rauch, Nora\n",
      "Rukhlenko, Oleksii\n",
      "Kholodenko, Boris N\n",
      "Iglesias-Martinez, Luis F\n",
      "Ryan, Colm J\n",
      "Pilkington, Ruth\n",
      "Cammareri, Patrizia\n",
      "Sansom, Owen\n",
      "Shave, Steven\n",
      "Auer, Manfred\n",
      "Horn, Nicola\n",
      "Klose, Franziska\n",
      "Ueffing, Marius\n",
      "Boldt, Karsten\n",
      "Lynn, David J\n",
      "Kolch, Walter\n",
      "2020-01-01-Extensive-rewiring-of-the-EGFR-network-in-colorectal-cancer-cells-expressing-transforming-levels-of-KRASG13D.md 122\n",
      "SUCESSFULLY PARSED kennedy2020extensive: \" Extensive rewiring of the EGFR network in colorectal cancer  ... \"\n",
      "Shave, Steven\n",
      "Pham, Nhan T\n",
      "{\\'S}mieja, Connor B\n",
      "Auer, Manfred\n",
      "2020-01-01-Quantitative-microdialysis-experimental-protocol-and-software-for-small-molecule-protein-affinity-determination-and-for-exclusion-of-compounds-with-poor-physicochemical-properties.md 193\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../_publications/2020-01-01-Quantitative-microdialysis-experimental-protocol-and-software-for-small-molecule-protein-affinity-determination-and-for-exclusion-of-compounds-with-poor-physicochemical-properties.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steve\\Documents\\Repos\\stevenshave.github.io\\markdown_generator\\PubsFromBib.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/Documents/Repos/stevenshave.github.io/markdown_generator/PubsFromBib.ipynb#W4sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m md_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(md_filename)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/Documents/Repos/stevenshave.github.io/markdown_generator/PubsFromBib.ipynb#W4sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39mprint\u001b[39m(md_filename, \u001b[39mlen\u001b[39m(md_filename))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/steve/Documents/Repos/stevenshave.github.io/markdown_generator/PubsFromBib.ipynb#W4sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m../_publications/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m md_filename, \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/steve/Documents/Repos/stevenshave.github.io/markdown_generator/PubsFromBib.ipynb#W4sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     f\u001b[39m.\u001b[39mwrite(md)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/steve/Documents/Repos/stevenshave.github.io/markdown_generator/PubsFromBib.ipynb#W4sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSUCESSFULLY PARSED \u001b[39m\u001b[39m{\u001b[39;00mbib_id\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m'\u001b[39m, b[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m][:\u001b[39m60\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m(\u001b[39mlen\u001b[39m(b[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m>\u001b[39m\u001b[39m60\u001b[39m),\u001b[39m\"\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\steve\\miniconda3\\envs\\rdkit\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../_publications/2020-01-01-Quantitative-microdialysis-experimental-protocol-and-software-for-small-molecule-protein-affinity-determination-and-for-exclusion-of-compounds-with-poor-physicochemical-properties.md'"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                print(author)\n",
    "                citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = str(os.path.basename(md_filename))[:100]\n",
    "            print(md_filename, len(md_filename))\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
